#!/usr/bin/env python3
"""
è®¡ç®—åŸå§‹FPDM UNetå’ŒHAE UNetçš„å‚æ•°é‡å¯¹æ¯”
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
from guided_diffusion.unet_v2 import UNetModel  # åŸå§‹FPDM UNet
from guided_diffusion.unet_hae import HAEUNetModel  # HAE UNet
from guided_diffusion.unet_hae_lite import HAEUNetModelLite  # HAE UNet Lite

def count_parameters(model):
    """è®¡ç®—æ¨¡å‹çš„æ€»å‚æ•°é‡"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def format_params(num_params):
    """æ ¼å¼åŒ–å‚æ•°æ•°é‡æ˜¾ç¤º"""
    if num_params >= 1e9:
        return f"{num_params/1e9:.1f}B"
    elif num_params >= 1e6:
        return f"{num_params/1e6:.1f}M"
    elif num_params >= 1e3:
        return f"{num_params/1e3:.1f}K"
    else:
        return str(num_params)

def create_model_configs():
    """åˆ›å»ºæ¨¡å‹é…ç½®"""
    # æ ‡å‡†é…ç½®ï¼ŒåŸºäºBraTSæ•°æ®é›†
    config = {
        'image_size': 128,
        'in_channels': 4,
        'model_channels': 128,
        'out_channels': 4,
        'num_res_blocks': 2,
        'attention_resolutions': "32,16,8",
        'dropout': 0.1,
        'channel_mult': (1, 2, 4, 8),
        'conv_resample': True,
        'dims': 2,
        'num_classes': None,
        'use_checkpoint': False,
        'use_fp16': False,
        'num_heads': 8,
        'num_head_channels': -1,
        'num_heads_upsample': -1,
        'use_scale_shift_norm': False,
        'resblock_updown': False,
        'use_new_attention_order': False,
        'clf_free': True,
    }
    
    # å¤„ç†attention_resolutions
    attention_resolutions = []
    for res in config['attention_resolutions'].split(","):
        attention_resolutions.append(config['image_size'] // int(res))
    config['attention_resolutions'] = attention_resolutions
    
    return config

def test_model_functionality(model, model_name):
    """æµ‹è¯•æ¨¡å‹åŠŸèƒ½"""
    print(f"\næµ‹è¯• {model_name} åŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    x = torch.randn(batch_size, 4, 128, 128)
    timesteps = torch.randint(0, 1000, (batch_size,))
    
    try:
        with torch.no_grad():
            if 'HAE' in model_name:
                output = model(x, timesteps, clf_free=True)
            else:
                output = model(x, timesteps, clf_free=True)
        
        print(f"âœ… {model_name} å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
        return True
        
    except Exception as e:
        print(f"âŒ {model_name} å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False

def main():
    print("=" * 60)
    print("åŸå§‹FPDM UNet vs HAE UNet å‚æ•°é‡å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    
    # è·å–æ¨¡å‹é…ç½®
    config = create_model_configs()
    print(f"\næ¨¡å‹é…ç½®:")
    print(f"  å›¾åƒå°ºå¯¸: {config['image_size']}x{config['image_size']}")
    print(f"  è¾“å…¥é€šé“: {config['in_channels']}")
    print(f"  æ¨¡å‹é€šé“: {config['model_channels']}")
    print(f"  æ³¨æ„åŠ›åˆ†è¾¨ç‡: {config['attention_resolutions']}")
    print(f"  é€šé“å€æ•°: {config['channel_mult']}")
    
    models = {}
    
    try:
        # 1. åŸå§‹FPDM UNet (unet_v2.py)
        print(f"\nåˆ›å»ºåŸå§‹FPDM UNet...")
        original_config = config.copy()
        models['Original FPDM UNet'] = UNetModel(**original_config)
        
        # 2. HAE UNet
        print(f"åˆ›å»ºHAE UNet...")
        hae_config = config.copy()
        hae_config['use_hae'] = True
        models['HAE UNet'] = HAEUNetModel(**hae_config)
        
        # 3. HAE UNet Lite
        print(f"åˆ›å»ºHAE UNet Lite...")
        hae_lite_config = config.copy()
        hae_lite_config['use_hae'] = True
        models['HAE UNet Lite'] = HAEUNetModelLite(**hae_lite_config)
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    print(f"\n" + "=" * 60)
    print("å‚æ•°é‡ç»Ÿè®¡")
    print("=" * 60)
    
    results = {}
    
    for name, model in models.items():
        try:
            param_count = count_parameters(model)
            results[name] = param_count
            
            print(f"\n{name}:")
            print(f"  æ€»å‚æ•°é‡: {format_params(param_count)} ({param_count:,})")
            
            # æµ‹è¯•æ¨¡å‹åŠŸèƒ½
            test_model_functionality(model, name)
            
        except Exception as e:
            print(f"âŒ {name} å‚æ•°è®¡ç®—å¤±è´¥: {e}")
    
    # å¯¹æ¯”åˆ†æ
    if len(results) >= 2:
        print(f"\n" + "=" * 60)
        print("å¯¹æ¯”åˆ†æ")
        print("=" * 60)
        
        original_params = results.get('Original FPDM UNet', 0)
        hae_params = results.get('HAE UNet', 0)
        hae_lite_params = results.get('HAE UNet Lite', 0)
        
        if original_params > 0:
            print(f"\nğŸ“Š å‚æ•°é‡å¯¹æ¯” (ä»¥åŸå§‹FPDM UNetä¸ºåŸºå‡†):")
            print(f"  åŸå§‹FPDM UNet:     {format_params(original_params)} (åŸºå‡†)")
            
            if hae_params > 0:
                hae_ratio = hae_params / original_params
                hae_diff = hae_params - original_params
                print(f"  HAE UNet:          {format_params(hae_params)} ({hae_ratio:.2f}x, {'+' if hae_diff > 0 else ''}{format_params(abs(hae_diff))})")
            
            if hae_lite_params > 0:
                lite_ratio = hae_lite_params / original_params
                lite_diff = hae_lite_params - original_params
                print(f"  HAE UNet Lite:     {format_params(hae_lite_params)} ({lite_ratio:.2f}x, {'+' if lite_diff > 0 else ''}{format_params(abs(lite_diff))})")
        
        if hae_params > 0 and hae_lite_params > 0:
            lite_vs_hae_ratio = hae_lite_params / hae_params
            lite_vs_hae_diff = hae_lite_params - hae_params
            print(f"\nğŸ” HAE Lite vs HAE å¯¹æ¯”:")
            print(f"  å‚æ•°å‡å°‘: {format_params(abs(lite_vs_hae_diff))} ({(1-lite_vs_hae_ratio)*100:.1f}% å‡å°‘)")
            print(f"  å‹ç¼©æ¯”: {1/lite_vs_hae_ratio:.2f}x")
    
    print(f"\n" + "=" * 60)
    print("æ€»ç»“")
    print("=" * 60)
    
    print(f"\nâœ… åˆ†æå®Œæˆ!")
    print(f"\nğŸ“‹ å…³é”®å‘ç°:")
    if original_params > 0:
        print(f"  â€¢ åŸå§‹FPDM UNetæ˜¯åŸºç¡€æ¨¡å‹ï¼Œå‚æ•°é‡ä¸º {format_params(original_params)}")
    if hae_params > 0 and original_params > 0:
        increase_pct = ((hae_params - original_params) / original_params) * 100
        print(f"  â€¢ HAE UNeté€šè¿‡æ·»åŠ Transformerå¢åŠ äº† {increase_pct:.1f}% çš„å‚æ•°")
    if hae_lite_params > 0 and hae_params > 0:
        reduction_pct = ((hae_params - hae_lite_params) / hae_params) * 100
        print(f"  â€¢ HAE UNet Liteé€šè¿‡å…±äº«æŠ•å½±å±‚å‡å°‘äº† {reduction_pct:.1f}% çš„HAEå‚æ•°")
    
    print(f"\nğŸ¯ å»ºè®®:")
    print(f"  â€¢ å¦‚éœ€åŸºç¡€æ‰©æ•£æ¨¡å‹åŠŸèƒ½ï¼Œä½¿ç”¨åŸå§‹FPDM UNet")
    print(f"  â€¢ å¦‚éœ€æ›´å¼ºç‰¹å¾æå–èƒ½åŠ›ï¼Œä½¿ç”¨HAE UNet")
    print(f"  â€¢ å¦‚éœ€å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡ï¼Œä½¿ç”¨HAE UNet Lite")

if __name__ == "__main__":
    main()