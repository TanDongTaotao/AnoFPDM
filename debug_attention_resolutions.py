#!/usr/bin/env python3
"""
è°ƒè¯•HAEæ¨¡å‹çš„attention_resolutionsé—®é¢˜
"""

import torch
import torch.nn as nn
from guided_diffusion.unet_hae_lite import HAEUNetModelLite
from guided_diffusion.unet_hae_v2 import HAEUNetModelV2
from guided_diffusion.unet_hae import HAEUNetModel

def debug_model_construction(model_class, model_name):
    """
    è°ƒè¯•æ¨¡å‹æ„å»ºè¿‡ç¨‹ä¸­çš„åˆ†è¾¨ç‡è®¡ç®—
    """
    print(f"\nğŸ” è°ƒè¯• {model_name} çš„åˆ†è¾¨ç‡è®¡ç®—...")
    
    # æ¨¡å‹é…ç½®
    config = {
        'image_size': 64,
        'in_channels': 3,
        'model_channels': 128,
        'out_channels': 3,
        'num_res_blocks': 2,
        'attention_resolutions': (1, 2, 4, 8),
        'dropout': 0.0,
        'channel_mult': (1, 2, 4, 8),
        'use_checkpoint': False,
        'use_fp16': False,
        'num_heads': 4,
        'num_head_channels': 32,
        'use_scale_shift_norm': True,
        'resblock_updown': False,
        'use_new_attention_order': False,
        'clf_free': True,
        'use_hae': True,
    }
    
    # æ·»åŠ V2ç‰¹æœ‰çš„å‚æ•°
    if 'V2' in model_name:
        config['bottleneck_ratio'] = 0.25
    
    print(f"   é…ç½®çš„attention_resolutions: {config['attention_resolutions']}")
    print(f"   é…ç½®çš„channel_mult: {config['channel_mult']}")
    print(f"   é…ç½®çš„num_res_blocks: {config['num_res_blocks']}")
    
    # æ‰‹åŠ¨è®¡ç®—åˆ†è¾¨ç‡å˜åŒ–
    print("\n   ğŸ“ æ‰‹åŠ¨è®¡ç®—åˆ†è¾¨ç‡å˜åŒ–:")
    image_size = config['image_size']
    channel_mult = config['channel_mult']
    num_res_blocks = config['num_res_blocks']
    
    ds = 1  # å½“å‰ä¸‹é‡‡æ ·å€æ•°
    current_resolution = image_size
    
    print(f"   åˆå§‹åˆ†è¾¨ç‡: {current_resolution}, ds={ds}")
    
    # ç¼–ç å™¨åˆ†è¾¨ç‡è®¡ç®—
    for level, mult in enumerate(channel_mult):
        print(f"\n   Level {level} (mult={mult}):")
        
        # æ¯ä¸ªlevelæœ‰num_res_blocksä¸ªResBlock
        for block_idx in range(num_res_blocks):
            print(f"     ResBlock {block_idx}: åˆ†è¾¨ç‡={current_resolution}, ds={ds}")
            if ds in config['attention_resolutions']:
                print(f"       -> åº”è¯¥æ·»åŠ AttentionBlock (ds={ds} in {config['attention_resolutions']})")
            else:
                print(f"       -> ä¸æ·»åŠ AttentionBlock (ds={ds} not in {config['attention_resolutions']})")
        
        # é™¤äº†æœ€åä¸€ä¸ªlevelï¼Œéƒ½æœ‰ä¸‹é‡‡æ ·
        if level != len(channel_mult) - 1:
            ds *= 2
            current_resolution //= 2
            print(f"     ä¸‹é‡‡æ ·å: åˆ†è¾¨ç‡={current_resolution}, ds={ds}")
    
    print(f"\n   ä¸­é—´å—: åˆ†è¾¨ç‡={current_resolution}, ds={ds}")
    print(f"   -> ä¸­é—´å—æ€»æ˜¯æœ‰AttentionBlock")
    
    # åˆ›å»ºæ¨¡å‹å¹¶æ£€æŸ¥å®é™…ç»“æ„
    print(f"\n   ğŸ—ï¸  åˆ›å»º {model_name} æ¨¡å‹...")
    try:
        model = model_class(**config)
        print(f"   âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥ç¼–ç å™¨ä¸­çš„æ³¨æ„åŠ›å—
        encoder_attention_count = 0
        print(f"\n   ğŸ“¥ æ£€æŸ¥ç¼–ç å™¨ (input_blocks):")
        for i, block in enumerate(model.input_blocks):
            has_attention = False
            for layer in block:
                if hasattr(layer, '__class__') and 'AttentionBlock' in layer.__class__.__name__:
                    has_attention = True
                    encoder_attention_count += 1
                    break
            print(f"     Block {i}: {'æœ‰AttentionBlock' if has_attention else 'æ— AttentionBlock'}")
        
        # æ£€æŸ¥ä¸­é—´å—
        middle_attention_count = 0
        print(f"\n   ğŸ”„ æ£€æŸ¥ä¸­é—´å— (middle_block):")
        for i, layer in enumerate(model.middle_block):
            if hasattr(layer, '__class__') and 'AttentionBlock' in layer.__class__.__name__:
                middle_attention_count += 1
                print(f"     Layer {i}: AttentionBlock")
            else:
                print(f"     Layer {i}: {layer.__class__.__name__}")
        
        # æ£€æŸ¥è§£ç å™¨ä¸­çš„æ³¨æ„åŠ›å—
        decoder_attention_count = 0
        print(f"\n   ğŸ“¤ æ£€æŸ¥è§£ç å™¨ (output_blocks):")
        for i, block in enumerate(model.output_blocks):
            has_attention = False
            for layer in block:
                if hasattr(layer, '__class__') and 'AttentionBlock' in layer.__class__.__name__:
                    has_attention = True
                    decoder_attention_count += 1
                    break
            print(f"     Block {i}: {'æœ‰AttentionBlock' if has_attention else 'æ— AttentionBlock'}")
        
        print(f"\n   ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"     ç¼–ç å™¨AttentionBlockæ•°é‡: {encoder_attention_count}")
        print(f"     ä¸­é—´å—AttentionBlockæ•°é‡: {middle_attention_count}")
        print(f"     è§£ç å™¨AttentionBlockæ•°é‡: {decoder_attention_count}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def main():
    print("ğŸ” è°ƒè¯•HAEæ¨¡å‹çš„attention_resolutionsé—®é¢˜")
    print("="*60)
    
    models_to_test = [
        (HAEUNetModel, "HAE UNet (åŸç‰ˆ)"),
        (HAEUNetModelLite, "HAE UNet Lite"),
        (HAEUNetModelV2, "HAE UNet V2"),
    ]
    
    for model_class, model_name in models_to_test:
        debug_model_construction(model_class, model_name)
        print("="*60)

if __name__ == "__main__":
    main()